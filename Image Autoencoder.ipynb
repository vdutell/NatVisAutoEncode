{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{in} = F_{act}((Im+n_{in} W_{in}) + bias) $$\n",
    "$$ Im^* = F_{act}(y_{in} W_{in}^T) + n_{out} $$\n",
    "\n",
    "$$ Cost = \\sqrt{\\langle|Im-Im^*|\\rangle} + \\lambda \\langle r \\rangle $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.plotutils as plu\n",
    "import utils.imreadin as imr\n",
    "#import utils.dirutils as diru\n",
    "\n",
    "#code to reload\n",
    "import imp\n",
    "imp.reload(imr)\n",
    "\n",
    "#code to limit number of CPUs\n",
    "maxcpus = 1\n",
    "#%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "#image files\n",
    "ims = 'kyoto' # 'vanhateren' #\n",
    "patch_multiplier = 4\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.print_figure_kwargs = {'dpi' : 200} #plotting pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class aec_model(object):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        params = self.add_params(params)\n",
    "        self.params = params\n",
    "        self.make_dirs()\n",
    "        self.graph = self.make_graph()\n",
    "\n",
    "    def add_params(self, params):\n",
    "        params['compression'] = params['imxlen'] * params['imylen'] / params['nneurons']\n",
    "        params['savefolder'] = str('./output/image_output/' + str(params['ims'])+\n",
    "                                   '_nonlin1_' + str(params['nonlin1'])+ \n",
    "                                   '_nonlin2_' + str(params['nonlin2'])+\n",
    "                                   '_neurons_'+ str(params['nneurons'])+\n",
    "                                   '_nin_'+ str(params['noise_x'])+\n",
    "                                   '_nout_'+ str(params['noise_r'])+\n",
    "                                   '_bsze_'+ str(params['batchsize'])+\n",
    "                                   '_epochs_'+ str(params['epochs'])+\n",
    "                                   '_lrate_'+ str(params['learning_rate'])+\n",
    "                                   '_lambda_act'+ str(params['lambda_act'])+\n",
    "                                   '_lambda_wgt' + str(params['lambda_wgt'])+ '/')\n",
    "        return(params)\n",
    "    \n",
    "    \n",
    "    def make_dirs(self):\n",
    "        if not os.path.exists(self.params['savefolder']):\n",
    "            os.makedirs(self.params['savefolder'])\n",
    "        else:\n",
    "            filelist = [f for f in os.listdir(self.params['savefolder'])]\n",
    "            for f in filelist:\n",
    "                os.remove(self.params['savefolder']+f)\n",
    "\n",
    "    def placeholder_inputs(self):\n",
    "        image_placeholder = tf.placeholder(tf.float32,\n",
    "                                           shape=(self.params[\"batchsize\"], self.params[\"imxlen\"] * self.params[\"imylen\"]))\n",
    "        return(image_placeholder)\n",
    "\n",
    "        \n",
    "    def make_graph(self):\n",
    "    \n",
    "        print('Compressing by {} for a total of {} neurons'.format(self.params['compression'],\n",
    "                                                                   self.params['nneurons']))\n",
    "        #setup our graph\n",
    "        mygraph = tf.Graph()\n",
    "        with mygraph.as_default():\n",
    "            #input images\n",
    "            with tf.name_scope('input'):\n",
    "                self.x = self.placeholder_inputs()\n",
    "            \n",
    "            #activation function type\n",
    "            with tf.name_scope('nonliearities'):\n",
    "                self.nonlin1 = self.params['nonlin1']\n",
    "                self.nonlin2  = self.params['nonlin2']\n",
    "\n",
    "            #noises\n",
    "            with tf.name_scope('noises'):\n",
    "                self.noisexsigma = self.params['noise_x']\n",
    "                self.noisersigma = self.params['noise_r']\n",
    "\n",
    "            #function to add noise\n",
    "            with tf.name_scope(\"add_noise\"):\n",
    "                def add_noise(input_layer, std):\n",
    "                    noise = tf.random_normal(shape=tf.shape(input_layer),\n",
    "                                             mean=0.0, stddev=std, dtype=tf.float32) \n",
    "                    return tf.add(input_layer,noise)\n",
    "            \n",
    "            #weights\n",
    "            with tf.variable_scope(\"weights\"):\n",
    "                weights_kernel_in = tf.random_normal(\n",
    "                        [self.params['imxlen']*self.params['imylen'],\n",
    "                         self.params['nneurons']],\n",
    "                        dtype=tf.float32,stddev=0.1)\n",
    "                \n",
    "                weights_kernel_out = tf.random_normal( \n",
    "                        [self.params['nneurons'],\n",
    "                         self.params['imxlen']*self.params['imylen']],\n",
    "                        dtype=tf.float32,stddev=0.1)\n",
    "                \n",
    "                self.win = tf.get_variable('win',initializer=weights_kernel_in)\n",
    "                self.wout = tf.get_variable('wout',initializer=weights_kernel_out)\n",
    "                \n",
    "            #bias\n",
    "            with tf.variable_scope(\"in_bias\"):\n",
    "                offset = 0 #to keep values positive\n",
    "                self.inbias = tf.Variable(tf.random_normal([self.params['nneurons']],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=0.1)+offset)\n",
    "            with tf.variable_scope(\"out_bias\"):\n",
    "                offset = 0\n",
    "                if(params['nonlin2']in['sigmoid','relu','tanh']):\n",
    "                    self.outbias = tf.Variable(tf.random_normal([self.params['imxlen']*self.params['imylen']],\n",
    "                                                                dtype=tf.float32,\n",
    "                                                                stddev=0.1)+offset)\n",
    "                else:\n",
    "                    self.outbias = tf.zeros([self.params['imxlen']*self.params['imylen']])\n",
    "            #lambda\n",
    "            with tf.name_scope('lambda_activation'):\n",
    "                self.lambda_act = self.params['lambda_act']\n",
    "                \n",
    "            #lambda2\n",
    "            with tf.name_scope('lambda_weights'):\n",
    "                self.lambda_wgt = self.params['lambda_wgt']                \n",
    "\n",
    "            #learning_rate\n",
    "            with tf.name_scope('learning_rate'):\n",
    "                self.learning_rate = self.params['learning_rate']\n",
    "\n",
    "            #nonlienarities\n",
    "            with tf.name_scope(\"nonlienarities\"):\n",
    "                #define nonlinearities\n",
    "                def tanh_fun(bias,arg):\n",
    "                    return tf.nn.tanh(tf.add(arg,bias)) \n",
    "                def sigmoid_fun(bias,arg):\n",
    "                    return tf.nn.sigmoid(tf.add(arg,bias)) \n",
    "                def relu_fun(bias,arg):\n",
    "                    return tf.nn.relu(tf.add(arg,bias)) \n",
    "                def no_fun(bias,arg):\n",
    "                    return arg\n",
    "\n",
    "            #encoding part of model\n",
    "            with tf.name_scope(\"encoding\"):\n",
    "                #add noise to input, and multiply by weights\n",
    "                linearin = tf.matmul(add_noise(self.x,self.params['noise_x']),self.win) \n",
    "                self.yin = tf.case({tf.equal(self.nonlin1,'tanh'):\n",
    "                                    (lambda: tanh_fun(self.inbias,linearin)),\n",
    "                                    tf.equal(self.nonlin1,'sigmoid'):\n",
    "                                    (lambda: sigmoid_fun(self.inbias,linearin)),\n",
    "                                    tf.equal(self.nonlin1,'relu'):\n",
    "                                    (lambda: relu_fun(self.inbias,linearin))},\n",
    "                                   default=(lambda: no_fun(self.inbias,linearin)),\n",
    "                                   exclusive=True)\n",
    "                self.yin_noised = add_noise(self.yin,self.params['noise_r'])\n",
    "\n",
    "\n",
    "            #output part of model\n",
    "            with tf.name_scope(\"decoding\"):\n",
    "                #calculate output (reconstruction)\n",
    "                #add noise to inner layer, and multiply by weight  transpose\n",
    "                linearout = tf.matmul(self.yin_noised,self.wout) \n",
    "                self.xp = tf.case({tf.equal(self.nonlin2,'tanh'):\n",
    "                                   (lambda: tanh_fun(self.outbias,linearout)),\n",
    "                                   tf.equal(self.nonlin2,'sigmoid'):\n",
    "                                   (lambda: sigmoid_fun(self.outbias,linearout)),\n",
    "                                   tf.equal(self.nonlin2,'relu'):\n",
    "                                   (lambda: relu_fun(self.outbias,linearout))},\n",
    "                                  default=(lambda: no_fun(self.outbias,linearout)),\n",
    "                                   exclusive=True, name='output_nonlienarity')\n",
    "            \n",
    "            #how well are we reconstructing?\n",
    "            with tf.name_scope(\"reconstruction\"):\n",
    "                self.normalize_recon = False\n",
    "                if self.normalize_recon == True:\n",
    "                    normx = self.x - tf.reduce_min(self.x,axis=0)\n",
    "                    normxp = self.xp - tf.reduce_min(self.xp, axis=0)\n",
    "                else:\n",
    "                    normx = self.x\n",
    "                    normxp = self.xp\n",
    "                #caclculate redonstruction error.\n",
    "                self.recon_err = tf.norm(normx-normxp,ord=2)\n",
    "\n",
    "            #calculate cost\n",
    "            with tf.name_scope(\"cost_function\"):\n",
    "                self.activation = tf.reduce_mean(self.yin,axis=0)\n",
    "                self.cost = (tf.reduce_mean(self.recon_err) +\n",
    "                             self.lambda_act * tf.norm(self.activation,ord=1) + \n",
    "                             self.lambda_wgt * tf.norm(self.wout, ord=1))                     \n",
    "            #train our model\n",
    "            with tf.name_scope(\"training_step\"):\n",
    "                self.train_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "                #self.train_step = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(self.cost)\n",
    "                \n",
    "            # create a summary for our cost, im, reconstruction, & weights\n",
    "            with tf.name_scope('cost_viz'):\n",
    "                tf.summary.scalar(\"cost\", self.cost)\n",
    "\n",
    "            with tf.name_scope('image_viz'):    \n",
    "                x_t = tf.reshape(self.x,(self.params['batchsize'],self.params['imxlen'],self.params['imylen'],1))\n",
    "                tf.summary.image(\"image\", x_t, max_outputs=self.params[\"batchsize\"])\n",
    "\n",
    "            with tf.name_scope('recon_viz'):\n",
    "                xp_t = tf.reshape(self.xp, (self.params['batchsize'],\n",
    "                                            self.params['imxlen'],\n",
    "                                            self.params['imylen'],\n",
    "                                            1))\n",
    "                tf.summary.image(\"recon\", xp_t,max_outputs=self.params[\"batchsize\"])\n",
    "\n",
    "            with tf.name_scope('inweights_viz'):    \n",
    "                inwin_t = tf.reshape(tf.transpose(self.win),\n",
    "                                   (self.params['nneurons'],\n",
    "                                    self.params['imxlen'],\n",
    "                                    self.params['imylen'],1))\n",
    "                tf.summary.image(\"inweights\", inwin_t, max_outputs=self.params['nneurons'])\n",
    "                \n",
    "            with tf.name_scope('outweights_viz'):    \n",
    "                outwin_t = tf.reshape(self.wout,\n",
    "                                   (self.params['nneurons'],\n",
    "                                    self.params['imxlen'],\n",
    "                                    self.params['imylen'],1))\n",
    "                tf.summary.image(\"outweights\", outwin_t, max_outputs=self.params['nneurons'])\n",
    "\n",
    "            # merge all summaries into a single \"operation\" which we can execute in a session \n",
    "            self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "        return(mygraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make session and train model\n",
    "def train_model(aec):\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True #don't allocate the entire GPU's memory\n",
    "        config.log_device_placement=True #tell me where devices are placed\n",
    "        \n",
    "        aec.filename_queue = tf.train.string_input_producer(\n",
    "            [aec.params['tfrecordfilename']], \n",
    "            num_epochs=aec.params['epochs'],\n",
    "            shuffle = True)\n",
    "\n",
    "        aec.inputdataset = tf.contrib.data.TFRecordDataset(filenames = aec.params['tfrecordfilename'])\n",
    "\n",
    "        #initialize vars\n",
    "        aec.iterator =  tf.contrib.data.Iterator.from_structure(\n",
    "            aec.inputdataset.output_types,\n",
    "            aec.inputdataset.output_shapes)\n",
    "        next_element = aec.iterator.get_next()\n",
    "\n",
    "        # iterator = vhimgs.make_initializable_iterator()\n",
    "        # next_element = iterator.get_next()\n",
    "\n",
    "        # create two initialization ops to switch between the datasets\n",
    "        init_op = aec.iterator.make_initializer(aec.inputdataset)\n",
    "\n",
    "        with tf.Session(graph = aec.graph, config=config) as sess:\n",
    "\n",
    "            sess.run(init_op)\n",
    "\n",
    "            #summary writer for tensorboard\n",
    "            writer = tf.summary.FileWriter(aec.params['savefolder'],\n",
    "                                           graph=tf.get_default_graph())\n",
    "\n",
    "            #save evolution of system over training\n",
    "            cost_evolution = []\n",
    "            wmean_evolution = []\n",
    "\n",
    "            inweights_evolution = []\n",
    "            outweights_evolution = []\n",
    "            inbias_evolution = []\n",
    "            activation_evolution = []\n",
    "            #gamma_evolution = []\n",
    "            #gamma_assign_evolution = []\n",
    "\n",
    "            activations = []\n",
    "\n",
    "            images = []\n",
    "            recons = []\n",
    "            print('neurons={}, noise_in={}, noise_out={}, lambda_w={}, lambda_act={}'\n",
    "                  .format(aec.params['nneurons'],\n",
    "                      aec.params['noise_x'],\n",
    "                      aec.params['noise_r'],\n",
    "                      aec.params['lambda_wgt'],\n",
    "                      aec.params['lambda_act']))\n",
    "\n",
    "            print('Training {} epochs... '.format(aec.params['epochs']))\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    #run our session\n",
    "                    elem = sess.run(next_element)\n",
    "\n",
    "                    #save evolution of params\n",
    "                    objcost, inws, acts = sess.run([aec.recon_err, aec.win, aec.yin], feed_dict=feeddict)  #aec.cost\n",
    "                    cost_evolution.append(objcost)\n",
    "                    wmean_evolution.append(np.mean(np.abs(inws)))\n",
    "\n",
    "                    activations.append(np.mean(acts))\n",
    "\n",
    "                    #dump our params\n",
    "                    win, wout, img, recon, inbias, activation = sess.run([aec.win, aec.wout, aec.x, aec.xp, aec.inbias, aec.activation])\n",
    "\n",
    "                    #save our weights, image, and reconstruction\n",
    "                    inweights_evolution.append(win)\n",
    "                    outweights_evolution.append(wout)\n",
    "                    inbias_evolution.append(inbias)\n",
    "                    activation_evolution.append(activation)\n",
    "\n",
    "                    imshape = [aec.params['batchsize'],\n",
    "                               aec.params['imxlen'],\n",
    "                               aec.params['imylen']]           \n",
    "                    images.append(np.reshape(img, imshape))\n",
    "                    recons.append(np.reshape(recon, imshape))\n",
    "                except tf.errors.OutofRangeError:\n",
    "                    print('End epoch')              \n",
    "\n",
    "            #summarize final params\n",
    "            print('Saving...')\n",
    "            summary, objcost, inws, outws, acts = sess.run([aec.summary_op, aec.cost, aec.win, aec.wout, aec.yin], feed_dict=feeddict)\n",
    "            cost_evolution.append(objcost)\n",
    "            wmean_evolution.append(np.mean(inws))\n",
    "            activations.append(np.mean(acts))\n",
    "            final_inweights = aec.win\n",
    "            final_outweights = aec.wout\n",
    "            writer.add_summary(summary,ii)\n",
    "            writer.close()\n",
    "\n",
    "            print('Done!')\n",
    "\n",
    "            return(cost_evolution,\n",
    "                   activations,\n",
    "                   wmean_evolution,\n",
    "                   inweights_evolution,\n",
    "                   outweights_evolution,\n",
    "                   images,\n",
    "                   recons,\n",
    "                   final_inweights,\n",
    "                   final_outweights,\n",
    "                   inbias_evolution, \n",
    "                   activation_evolution\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set parameters for parameter sweep\n",
    "params = {} #make a dictionary\n",
    "\n",
    "#parameters constant for all\n",
    "params[\"patchsize\"] = 16\n",
    "params[\"ims\"] = ims\n",
    "params[\"patch_multiplier\"] = patch_multiplier\n",
    "params['tfrecordfilename'] = imr.getrecordfilename(params[\"ims\"],\n",
    "                                                   params[\"patchsize\"],\n",
    "                                                   params[\"patch_multiplier\"])\n",
    "\n",
    "#params['tfrecord'] = imr.loadrecord(params[\"ims\"],\n",
    "#                                              params[\"patchsize\"],\n",
    "#                                              params[\"patch_multiplier\"])\n",
    "\n",
    "\n",
    "#with tf.device('/cpu:0'):\n",
    "#    try:\n",
    "#        vhimgs\n",
    "#    except NameError:\n",
    "#        vhimgs, params[\"patchsize\"] = imr.check_n_load_ims(params['ims'], params['patchsize'], params['patch_multiplier'])\n",
    "\n",
    "#params[\"nimages\"] = np.shape(vhimgs)[0]\n",
    "params[\"imxlen\"] = params[\"patchsize\"]\n",
    "params[\"imylen\"] = params[\"patchsize\"]\n",
    "\n",
    "#params for sweeping\n",
    "sweep_neurons = [64,100]\n",
    "sweep_nonlin1 = ['sigmoid']\n",
    "sweep_nonlin2 = ['linear']\n",
    "sweep_lambda_wgt = [0,0.01,0.1,0.5] #[0 , 0.1] #, 0.01, 0.005] #, 0, 0.1, 0.01, 0.005 #0, 0.1, \n",
    "sweep_lambda_act = [0,0.01,0.1,0.5] #[0.001, 0.0005, 0.0001] #[0.0, 0.02, 0.05, 0.1, 0.01, 0.005] #0.02, 0.05, 0.1, 0.01, 0.005\n",
    "#sweep_alpha = [0.0, 0.0001, 0.001, 0.01] #, 0.1, 1.0]\n",
    "batchsize = 100 #[100, 500, 1000] #100, 1000\n",
    "#sweep_batch_its = [[bsz, int((np.int(params['nimages']/bsz)))] for bsz in bsis] \n",
    "sweep_epochs = [50]\n",
    "sweep_learning_rates = [0.001] #, 0.001, 0.005, 0.01, 0.015] \n",
    "sweep_noise_xs_rs = [[0.,0.],[0.1,0.5],[0.2,1],[0.5,2]] #[[0.,0.], [0.05,0.5], [0.2,1], [0.3,2.5]] #[0.,0.], [0.05,0.5], [0.2,1], [0.3,2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing by 4.0 for a total of 64 neurons\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'MakeIterator_1' type=MakeIterator> cannot be interpreted as a Tensor. (Operation name: \"MakeIterator_1\"\nop: \"MakeIterator\"\ninput: \"TFRecordDataset_1\"\ninput: \"Iterator_2\"\ndevice: \"/device:GPU:0\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 270\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    271\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2707\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2708\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2791\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2792\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2793\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation name: \"MakeIterator_1\"\nop: \"MakeIterator\"\ninput: \"TFRecordDataset_1\"\ninput: \"Iterator_2\"\ndevice: \"/device:GPU:0\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7c012d931fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m                                  \u001b[0mfinal_outweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                                  \u001b[0minbias_evolution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                                  activation_evolution] = train_model(aec)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                 \u001b[0;31m#save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab2a13134452>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(aec)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#summary writer for tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1109\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \"\"\"\n\u001b[1;32m    412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 277\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    278\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Operation 'MakeIterator_1' type=MakeIterator> cannot be interpreted as a Tensor. (Operation name: \"MakeIterator_1\"\nop: \"MakeIterator\"\ninput: \"TFRecordDataset_1\"\ninput: \"Iterator_2\"\ndevice: \"/device:GPU:0\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "for neurons in sweep_neurons:\n",
    "    params['nneurons'] = neurons\n",
    "    for nonlin1 in sweep_nonlin1:\n",
    "        params['nonlin1'] = nonlin1\n",
    "        for nonlin2 in sweep_nonlin2:\n",
    "            params['nonlin2'] = nonlin2\n",
    "            for lambda_wgt in sweep_lambda_wgt:\n",
    "                params['lambda_wgt'] = lambda_wgt\n",
    "                for lambda_act in sweep_lambda_act:\n",
    "                    params['lambda_act'] = lambda_act\n",
    "#                    for batchsize, iterations in sweep_batch_its:\n",
    "                    params['batchsize'] = batchsize\n",
    "#                    params['iterations'] = iterations\n",
    "                    for epos in sweep_epochs:\n",
    "                        params['epochs'] = epos\n",
    "                        for lr in sweep_learning_rates:\n",
    "                            params['learning_rate'] = lr\n",
    "                            for xs,rs in sweep_noise_xs_rs:\n",
    "                                params['noise_x'] = xs\n",
    "                                params['noise_r'] = rs\n",
    "\n",
    "                                #make our model\n",
    "                                params['input_placeholder'] = tf.placeholder(tf.float32,\n",
    "                                                                   [params['patchsize'], \n",
    "                                                                    params['patchsize']])\n",
    "                                aec = aec_model(params)\n",
    "                                #train it'\n",
    "                                [cost_evolution,\n",
    "                                 activations,\n",
    "                                 wmean_evolution,\n",
    "                                 inweights_evolution,\n",
    "                                 outweights_evolution,\n",
    "                                 images,\n",
    "                                 recons,\n",
    "                                 final_inweights,\n",
    "                                 final_outweights, \n",
    "                                 inbias_evolution, \n",
    "                                 activation_evolution] = train_model(aec)\n",
    "\n",
    "                                #save model \n",
    "                                plu.save_plots(aec,\n",
    "                                               activations,\n",
    "                                               cost_evolution,\n",
    "                                               wmean_evolution,\n",
    "                                               inweights_evolution,\n",
    "                                               outweights_evolution,\n",
    "                                               images,\n",
    "                                               recons,\n",
    "                                               final_inweights,\n",
    "                                               final_outweights,\n",
    "                                               inbias_evolution, \n",
    "                                               activation_evolution)\n",
    "print(\"*** Parameter Sweep Finished! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(vhimgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inweights_evolution_r = np.rollaxis(np.reshape(inweights_evolution,\n",
    "                                                 (len(inweights_evolution),\n",
    "                                                  aec.params['imxlen'],\n",
    "                                                  aec.params['imylen'],\n",
    "                                                    aec.params['nneurons'])),3,1)\n",
    "\n",
    "\n",
    "plu.display_data_tiled(inweights_evolution_r[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
